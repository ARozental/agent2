{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import tokenize as tnk\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = tfds.load('imdb_reviews', with_info=True,\n",
    "#                                as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_to_gen(file_object):\n",
    "    while True:\n",
    "        data = file_object.readline()[:-2] #remove /n\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n",
    "f = open('train_data87.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "    docs_to_gen(f), target_vocab_size=2**11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.encode(\"I \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'had '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_en.decode([35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en.save_to_file(\"my_tok_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newline'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.features.text.SubwordTextEncoder.load_from_file(\"my_tok_test\").decode([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So many times have I walked on ruins , the remainings of places that I loved and got used to.. At first I was scared , each time I could feel my city , my current generation collapse , break into the black hole that thrives within it , I could feel humanity , the way I 'm able to feel my body.. After a few hundred years , the pattern became obvious , no longer the war and damage that would devastate me over and over again in the far past was effecting me so dominantly . <newline> It 's funny , but I felt as if after gaining what I desired so long , what I have lived for my entire life , only then , when I achieved immortality I started truly aging . <newline> <newline> 5 world wars have passed , and now they feel like a simple sickeness that would pass by every so often , I could no longer evaluate the individual human as a being of its own , the importance of mortals is merely the same as the importance of my skin cells ; They are a part of a mechanism so much more advanced , a mechanism that is so dear to my fallen heart a mechanism that I have seen fall and rise so many times , a mechanism that when lost all of which it had , had me loosing my will to live , for the first time in all of my thousands years of existence . <newline> <newline> Acceptance , something so important . a skill that has proved itself worthy dozens of times , an ability that looks so easy to achieve , a gift , that I was n't able to aquire in all my years , until now . When the ashes on the ground flew into the now empty air upon humanity 's fall , I felt as if all of it 's weight was crushing me . Ignorance took over and I searched years for a hope , a sign of the very same patterns that I used to watch reappear every hundred years , the very core of my will to exist that was now no more that I so strongly wish was . <newline> <newline> If you have ever wondered if silence can drive people crazy , it can.. <newline> I ca n't feel my legs , I have walked for days , just to hear the sound of gravel , crushed bones , crushed buildings and crushed civilizations under my steps to keep my sanity.. until I remembered , the day in my far past . The day of my rebirth , I took out of my pocket a small plastic box , with nine buttons and a small glass window . I could n't believe this was our past , I could n't believe how far we have been able to progress and yet , be destroyed by our own violence . <newline> I slowly dialed the number I was given , exactly 1729 years ago . <newline> <newline> I dropped a tear , a tear that was too slow to hit the ground as I got sucked into the darkness that emerged around me . <newline> <newline> A chill went through my spine as I saw my destiny rise above me , I could see the white teeth under the dark cloack ... <newline> <newline> `` You have finally arrived '' He projected into my mind , with the most chilling cold and unhuman voice . <newline> <newline> `` I 'm ready to obey '' I answered . I knew who was sitting infront of me , and it was time for me to obey him , after all these years of playing god , even I came to it . <newline> <newline> Funny is n't it ? Even by achieving immortality , death , is inescapable \""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('train_data87.txt')\n",
    "g = docs_to_gen(f)\n",
    "next(g)\n",
    "#next(g)\n",
    "#next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"I was feckin ' sloshed , mate . First time I ever was in the Big Lemon , and I 'd found me the best feckin ' pub I could imagine , I tell ya what . So I stumble out when it was closin ' time , musta been 'round 4 o'clock in the morning , and made my way through some alleys to find the quaint little AirBnB place I 'd rented for the week . <newline> <newline> A'course , that 's how many a horror story starts , ainnit ? But it was all fun and games at first . There was this bloke I saw comin ' towards me in the alley , dark as it was with only a few lights from some apartments overhead , where the folk were still awake . At least , I thought it was a bloke , but he looked more like there was n't something right with the whole alleyway . Like it was a painting someone had gone and ripped with a knife for some reason , fecked-up as it all looked , and the cut looked sort of weird and silvery , and wavy like a heat haze comin ' from a welder 's torch . <newline> <newline> Now this thing must 've been a good foot or five taller 'n me , but sloshed as I am , I just take off my hat and give it a good `` how-do-you-do '' , 'cause I 'm a nice fellow and I wan na pass , y'see ? Now this thing up and goes give me a `` mighty fine , how about y'self , sir ! '' I feckin ' quite pissed my britches ! More in surprise 'n anythin ' , really , but I keep my composure and just sorta try and pass 'm as he walks past me with his long , spindly legs as silvery as the rest of 'm , with his feet makin ' noises like he 's wearin ' cowboy boots with those thingies on 'm . But then that moment stupid old me finds I forgot my lighter at the pub , and so I turn and ask spindleboots there if he 's got some fire for me . <newline> <newline> Darn buggerer turns around on the spot faster 'n my eyes can see and says , he says `` sure ! I got your fire here . '' And the feckin ' thing stretches out one of his spindly legs and wraps it around me like a cobra and pulls me into itself . Devil 's pits , that felt like I was bein ' burnt layer of skin by layer . He sure got me with that . Good feckin ' joke , mate . <newline> <newline> Must 've been out like a light for ages , but when I woke up , I find myself here . So tell me , Doc : are time travellers really that sought after as subjects of study ? 'Cause I know you found me in your fancy cyberwebs database thing and I ca n't be three hundred years old as my passport would say if I had one , but I 'd really like to not die , y'know ? What do y'say , wan na go and grab a beer at the pub \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[float(y) for y in x] for x in l]\n",
    "\n",
    "def short_story_to_tokens(tokenizer,text):\n",
    "    paragraphs=text.split(\" <newline> <newline> \")\n",
    "    x = [[tokenizer_en.encode(sentence) for sentence in tnk.sent_tokenize(p)] for p in paragraphs]\n",
    "    return x\n",
    "y=short_story_to_tokens(tokenizer_en,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "f = open('train_data87.txt')\n",
    "g = docs_to_gen(f)\n",
    "#for xx in g:\n",
    "#    res.append(short_story_to_tokens(tokenizer_en,xx))\n",
    "res = [short_story_to_tokens(tokenizer_en,x) for x in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_stories = len(res)\n",
    "paragraphs = [len(x) for x in res]\n",
    "num_paragraphs = reduce(lambda x,y: x+y,paragraphs,0) / num_stories\n",
    "sentences = [[len(x) for x in p] for p in res]\n",
    "num_sentences = reduce(lambda x,y: x+y,flatten(sentences),0) / num_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_in_story = []\n",
    "s_in_p = []\n",
    "t_in_s = []\n",
    "for story in res:\n",
    "    p_in_story.append(len(story))\n",
    "    for p in story:\n",
    "        s_in_p.append(len(p))\n",
    "        for s in p:\n",
    "            t_in_s.append(len(s))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[36, 8, 47]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile = 0.95\n",
    "p_in_story_percentile = sorted(p_in_story)[0:int(len(p_in_story)*percentile)][-1]\n",
    "s_in_p_percentile = sorted(s_in_p)[0:int(len(s_in_p)*percentile)][-1]\n",
    "t_in_s_percentile = sorted(t_in_s)[0:int(len(t_in_s)*percentile)][-1]\n",
    "[p_in_story_percentile,s_in_p_percentile,t_in_s_percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
