return reconstruction vanishing loss
make tapes faster
print original and reconstructed text every n-th example
save model object
read from saved model
run on plumbus with big embedding


write generator
write memory
write descriminator
mask segments and not tokens??
write ragged transformer


add positional when ragged - currently we stop being ragged for it
make sure all calls to encoders and decoders are with the same type (ragged, not dense)
cut at max length-1 in make book dataset
have a version of book-dataset that only takes chapter2 because doing a full book takes inf time, 80 minutes for 20% of a book on 1 cpu
have vectors to tokens function => cut length for each level if token is closest to EoS

remove shift, only use batch
